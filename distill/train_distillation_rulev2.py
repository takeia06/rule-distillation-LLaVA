import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.amp import autocast
from torch.amp.grad_scaler import GradScaler
from functools import partial

from transformers import (
    AutoProcessor,
    AutoConfig,
    LlavaNextForConditionalGeneration,
    LlavaForConditionalGeneration,
    BitsAndBytesConfig,
    get_linear_schedule_with_warmup
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel

from PIL import Image
import os
import csv
from tqdm import tqdm
import time
import gc

# --- 1. è¨­å®šé …ç›® ---
TEACHER_MODEL_ID = "llava-hf/llava-v1.6-vicuna-7b-hf"
STUDENT_MODEL_ID = "llava-hf/llava-1.5-7b-hf"
TEACHER_ADAPTER_PATH = "checkpoints/llava-v1.6-vicuna-7b-lora-okvqa/checkpoint-2252"
STUDENT_ADAPTER_PATH = None
TRAIN_CSV_PATH = "data/VisA/chewinggum/full7/train.csv"
EVAL_CSV_PATH = "data/VisA/chewinggum/no/val.csv"
OUTPUT_DIR = "output/distilled_student_model_v15_final/"

# --- 2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (æ¨å¥¨è¨­å®š) ---
NUM_EPOCHS = 20
BATCH_SIZE = 1
GRAD_ACCUMULATION_STEPS = 8
LEARNING_RATE = 3e-4
TEMPERATURE = 1.0
LOSS_WEIGHT_LOGITS = 1.0
LOSS_WEIGHT_HIDDEN = 10.0
LORA_R = 16
LORA_ALPHA = 32
LORA_DROPOUT = 0.05
LORA_TARGET_MODULES = ["q_proj", "v_proj"]
WARMUP_STEPS = 20
# -------------------------------------------------------------

def load_models_and_processors():
    # (å¤‰æ›´ãªã—)
    print("1. æ•™å¸«ãƒ»ç”Ÿå¾’ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãã‚Œãã‚Œãƒ­ãƒ¼ãƒ‰ä¸­...")
    teacher_processor = AutoProcessor.from_pretrained(TEACHER_MODEL_ID)
    student_processor = AutoProcessor.from_pretrained(STUDENT_MODEL_ID)
    print("   >>> ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
    print("2. 8-bité‡å­åŒ–è¨­å®šã‚’æº–å‚™ä¸­...")
    quantization_config = BitsAndBytesConfig(load_in_8bit=True)
    print("   >>> é‡å­åŒ–è¨­å®šã®æº–å‚™å®Œäº†ï¼")
    print(f"3. æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ¼ã‚¹ '{TEACHER_MODEL_ID}' (8-bit) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    teacher_config = AutoConfig.from_pretrained(TEACHER_MODEL_ID)
    teacher_config.output_hidden_states = True
    try:
        image_grid_pinpoints = teacher_processor.image_processor.image_grid_pinpoints
        teacher_config.image_grid_pinpoints = image_grid_pinpoints
    except AttributeError: pass
    teacher_model = LlavaNextForConditionalGeneration.from_pretrained(TEACHER_MODEL_ID, config=teacher_config, quantization_config=quantization_config, torch_dtype=torch.float16)
    if TEACHER_ADAPTER_PATH:
        teacher_model = PeftModel.from_pretrained(teacher_model, TEACHER_ADAPTER_PATH)
        teacher_model = teacher_model.merge_and_unload()
    teacher_model.eval()
    print("   >>> æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
    print(f"4. ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ¼ã‚¹ '{STUDENT_MODEL_ID}' (8-bit LoRA) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    student_config = AutoConfig.from_pretrained(STUDENT_MODEL_ID)
    student_config.output_hidden_states = True
    student_model = LlavaForConditionalGeneration.from_pretrained(STUDENT_MODEL_ID, config=student_config, quantization_config=quantization_config, torch_dtype=torch.float16)
    if STUDENT_ADAPTER_PATH:
        student_model = PeftModel.from_pretrained(student_model, STUDENT_ADAPTER_PATH)
        student_model = student_model.merge_and_unload()
    print("5. ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«è’¸ç•™å­¦ç¿’ç”¨ã®LoRAã‚’é©ç”¨ä¸­...")
    student_model = prepare_model_for_kbit_training(student_model)
    lora_config = LoraConfig(r=LORA_R, lora_alpha=LORA_ALPHA, target_modules=LORA_TARGET_MODULES, lora_dropout=LORA_DROPOUT, bias="none", task_type="CAUSAL_LM")
    student_model = get_peft_model(student_model, lora_config)
    student_model.print_trainable_parameters()
    print("   >>> ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨LoRAã®é©ç”¨å®Œäº†ï¼\n")
    return teacher_model, student_model, teacher_processor, student_processor

### â˜… å¤‰æ›´ç‚¹ â˜… ###
# Datasetã®å½¹å‰²ã‚’ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã‚’è¨ˆç®—ã—ã¦è¿”ã™ã‚ˆã†ã«å¤‰æ›´
class StaticDistillationDataset(Dataset):
    def __init__(self, csv_path, teacher_processor, student_processor, is_train=True):
        self.teacher_processor = teacher_processor
        self.student_processor = student_processor
        self.is_train = is_train
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                self.tasks = list(csv.DictReader(f))
            print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {csv_path} ã‹ã‚‰ {len(self.tasks)} ä»¶ã®ã‚¿ã‚¹ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        except (FileNotFoundError, KeyError) as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{csv_path}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚'{e}'")
            self.tasks = []

    def __len__(self):
        return len(self.tasks)

    def __getitem__(self, idx):
        if not self.tasks: return None
        task = self.tasks[idx]
        image_path, instruction, output = task['image_path'], task['instruction'], task['output']
        
        try:
            image = Image.open(image_path).convert('RGB')
        except FileNotFoundError:
            print(f"è­¦å‘Š: ç”»åƒ '{image_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¿ã‚¹ã‚¯ {idx} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return None

        # æ•™å¸«ç”¨ã®å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã®éƒ¨åˆ†ã‚’ä½œæˆ
        teacher_full_prompt = f"USER: <image>\n{instruction}\nASSISTANT: {output}"
        teacher_prompt_only = f"USER: <image>\n{instruction}\nASSISTANT:"
        
        # ç”Ÿå¾’ç”¨ã®å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã®éƒ¨åˆ†ã‚’ä½œæˆ
        student_instruction = " " if self.is_train else instruction
        student_full_prompt = f"USER: <image>\n{student_instruction}\nASSISTANT: {output}"
        student_prompt_only = f"USER: <image>\n{student_instruction}\nASSISTANT:"

        # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã‚’å–å¾—
        teacher_inputs = self.teacher_processor(text=teacher_full_prompt, images=image, return_tensors="pt")
        teacher_prompt_len = self.teacher_processor(text=teacher_prompt_only, images=image, return_tensors="pt").input_ids.shape[1]

        student_inputs = self.student_processor(text=student_full_prompt, images=image, return_tensors="pt")
        student_prompt_len = self.student_processor(text=student_prompt_only, images=image, return_tensors="pt").input_ids.shape[1]

        image_sizes = teacher_inputs.get("image_sizes", torch.tensor([image.size]).to(torch.int64))

        return {
            "teacher_pixel_values": teacher_inputs.pixel_values.squeeze(0),
            "teacher_input_ids": teacher_inputs.input_ids.squeeze(0),
            "student_pixel_values": student_inputs.pixel_values.squeeze(0),
            "student_input_ids": student_inputs.input_ids.squeeze(0),
            "image_sizes": image_sizes.squeeze(0),
            "teacher_prompt_len": teacher_prompt_len,
            "student_prompt_len": student_prompt_len,
        }


def custom_collate_fn(batch, processor):
    """ç•°ãªã‚‹é•·ã•ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ãƒãƒƒãƒåŒ–ã™ã‚‹"""
    batch = [item for item in batch if item is not None]
    if not batch: return {}
    
    from torch.nn.utils.rnn import pad_sequence
    pad_token_id = processor.tokenizer.pad_token_id
    
    padded_batch = {}
    # å…¨ã¦ã®ã‚­ãƒ¼ã‚’ãƒ«ãƒ¼ãƒ—
    keys = batch[0].keys()
    for key in keys:
        items = [d[key] for d in batch]
        if "input_ids" in key:
            # å·¦å´ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            padded_batch[key] = pad_sequence(items, batch_first=True, padding_value=pad_token_id)
        elif "pixel_values" in key or "image_sizes" in key:
             padded_batch[key] = torch.stack(items)
        else: # prompt_len
             padded_batch[key] = torch.tensor(items)

    # attention_maskã‚’ç”Ÿæˆ
    padded_batch["teacher_attention_mask"] = (padded_batch["teacher_input_ids"] != pad_token_id).long()
    padded_batch["student_attention_mask"] = (padded_batch["student_input_ids"] != pad_token_id).long()
    
    return padded_batch

### â˜… å¤‰æ›´ç‚¹ â˜… ###
# æå¤±è¨ˆç®—é–¢æ•°ã‚’ã‚¹ãƒ©ã‚¤ã‚·ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã«å…¨é¢çš„ã«æ›¸ãæ›ãˆ
def calculate_distillation_loss(student_outputs, teacher_outputs, student_prompt_len, teacher_prompt_len):
    
    # å¿œç­”éƒ¨åˆ†ã®logitsã‚’ã‚¹ãƒ©ã‚¤ã‚¹
    # ãƒãƒƒãƒå†…ã®å„ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ãŒé•ã†å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãƒ«ãƒ¼ãƒ—ã§å‡¦ç†ï¼ˆãŸã ã—ãƒãƒƒãƒã‚µã‚¤ã‚º1ãªã‚‰ä¸è¦ï¼‰
    batch_size = student_outputs.logits.shape[0]
    loss_logits_list, loss_hidden_list = [], []

    for i in range(batch_size):
        s_prompt_len = student_prompt_len[i]
        t_prompt_len = teacher_prompt_len[i]

        s_logits_answer = student_outputs.logits[i, s_prompt_len:, :]
        t_logits_answer = teacher_outputs.logits[i, t_prompt_len:, :]
        
        answer_len = min(s_logits_answer.shape[0], t_logits_answer.shape[0])
        if answer_len == 0: continue

        s_logits_answer = s_logits_answer[:answer_len]
        t_logits_answer = t_logits_answer[:answer_len]

        # Logits Loss
        teacher_probs = F.softmax(t_logits_answer.float() / TEMPERATURE, dim=-1)
        student_log_probs = F.log_softmax(s_logits_answer.float() / TEMPERATURE, dim=-1)
        loss_logits_list.append(F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (TEMPERATURE ** 2))
        
        # Hidden Loss
        if student_outputs.hidden_states is not None and teacher_outputs.hidden_states is not None:
            num_layers = min(len(student_outputs.hidden_states[1:-1]), len(teacher_outputs.hidden_states[1:-1]))
            hidden_loss_per_item = 0
            for layer_idx in range(num_layers):
                s_hidden_answer = student_outputs.hidden_states[layer_idx+1][i, s_prompt_len:, :]
                t_hidden_answer = teacher_outputs.hidden_states[layer_idx+1][i, t_prompt_len:, :]
                s_hidden_answer = s_hidden_answer[:answer_len]
                t_hidden_answer = t_hidden_answer[:answer_len]

                s_hidden_norm = F.normalize(s_hidden_answer.float(), p=2, dim=-1)
                t_hidden_norm = F.normalize(t_hidden_answer.float(), p=2, dim=-1)
                hidden_loss_per_item += F.mse_loss(s_hidden_norm, t_hidden_norm)
            
            if num_layers > 0:
                loss_hidden_list.append(hidden_loss_per_item / num_layers)

    # ãƒãƒƒãƒå…¨ä½“ã®å¹³å‡æå¤±ã‚’è¨ˆç®—
    final_loss_logits = torch.stack(loss_logits_list).mean() if loss_logits_list else torch.tensor(0.0, device=student_outputs.logits.device)
    final_loss_hidden = torch.stack(loss_hidden_list).mean() if loss_hidden_list else torch.tensor(0.0, device=student_outputs.logits.device)

    return final_loss_logits, final_loss_hidden


def evaluate(student_model, teacher_model, dataloader, device):
    """
    ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’è¡Œã†é–¢æ•°ã€‚
    ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆOOMï¼‰ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã€è©•ä¾¡æ™‚ã®éš ã‚ŒçŠ¶æ…‹æå¤±ã®è¨ˆç®—ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚
    """
    student_model.eval()
    teacher_model.eval()
    total_eval_loss = 0
    total_logits_loss = 0
    
    # è©•ä¾¡æ™‚ã¯å‹¾é…è¨ˆç®—ãŒä¸è¦ãªã®ã§ã€torch.no_grad()ã§å…¨ä½“ã‚’å›²ã‚€
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            if not batch: continue
            for key, value in batch.items():
                if isinstance(value, torch.Tensor):
                    batch[key] = value.to(device)

            with autocast(device_type="cuda", dtype=torch.float16):
                # --- æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç† (éš ã‚ŒçŠ¶æ…‹ã¯ä¸è¦) ---
                teacher_inputs = {
                    "pixel_values": batch["teacher_pixel_values"], 
                    "input_ids": batch["teacher_input_ids"], 
                    "attention_mask": batch["teacher_attention_mask"], 
                    "image_sizes": batch["image_sizes"],
                    "output_hidden_states": False 
                }
                teacher_outputs = teacher_model(**teacher_inputs)
                
                # --- ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç† (éš ã‚ŒçŠ¶æ…‹ã¯ä¸è¦) ---
                student_inputs = {
                    "pixel_values": batch["student_pixel_values"], 
                    "input_ids": batch["student_input_ids"], 
                    "attention_mask": batch["student_attention_mask"],
                    "output_hidden_states": False
                }
                student_outputs = student_model(**student_inputs)

            # æå¤±è¨ˆç®—ã¯autocastã®å¤–ã§
            with autocast(device_type="cuda", enabled=False):
                # â˜… å¤‰æ›´ç‚¹: æå¤±è¨ˆç®—ã‚’å‘¼ã³å‡ºã™ã®ã§ã¯ãªãã€ã“ã“ã§ç›´æ¥è¨ˆç®—
                student_prompt_len = batch["student_prompt_len"]
                teacher_prompt_len = batch["teacher_prompt_len"]
                batch_size = student_outputs.logits.shape[0]
                
                for i in range(batch_size):
                    s_prompt_len = student_prompt_len[i]
                    t_prompt_len = teacher_prompt_len[i]
                    s_logits_answer = student_outputs.logits[i, s_prompt_len:, :]
                    t_logits_answer = teacher_outputs.logits[i, t_prompt_len:, :]
                    answer_len = min(s_logits_answer.shape[0], t_logits_answer.shape[0])
                    if answer_len == 0: continue
                    s_logits_answer = s_logits_answer[:answer_len]
                    t_logits_answer = t_logits_answer[:answer_len]
                    teacher_probs = F.softmax(t_logits_answer.float() / TEMPERATURE, dim=-1)
                    student_log_probs = F.log_softmax(s_logits_answer.float() / TEMPERATURE, dim=-1)
                    
                    loss_logits = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (TEMPERATURE ** 2)
                    total_logits_loss += loss_logits.item()

    avg_logits_loss = total_logits_loss / len(dataloader) if len(dataloader) > 0 else 0
    
    print(f"âœ… Eval Logits Loss: {avg_logits_loss:.4f}")
    return avg_logits_loss

def main():
    print("--- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ»ãƒ«ãƒ¼ãƒ«è’¸ç•™ (v15 è©•ä¾¡ãƒ«ãƒ¼ãƒ—ä¿®æ­£) ---")
    teacher_model, student_model, teacher_processor, student_processor = load_models_and_processors()
    device = student_model.device
    
    print("\n--- ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... ---")
    train_dataset = StaticDistillationDataset(csv_path=TRAIN_CSV_PATH, teacher_processor=teacher_processor, student_processor=student_processor, is_train=True)
    eval_dataset = StaticDistillationDataset(csv_path=EVAL_CSV_PATH, teacher_processor=teacher_processor, student_processor=student_processor, is_train=False)
    
    collate_fn_wrapped = partial(custom_collate_fn, processor=student_processor)
    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_wrapped)
    eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_wrapped)

    if not train_dataset.tasks:
        print("ã‚¨ãƒ©ãƒ¼: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    optimizer = torch.optim.AdamW(student_model.parameters(), lr=LEARNING_RATE)
    total_training_steps = (len(train_dataloader) // GRAD_ACCUMULATION_STEPS) * NUM_EPOCHS
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_training_steps)
    scaler = GradScaler(device='cuda')

    print("\n--- ğŸš€ å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼ ---")
    for epoch in range(NUM_EPOCHS):
        print(f"\n--- Epoch {epoch + 1}/{NUM_EPOCHS} ---")
        student_model.train()
        total_train_loss = 0
        pbar = tqdm(train_dataloader, desc=f"Training Epoch {epoch+1}")
        for step, batch in enumerate(pbar):
            if not batch: continue
            for key, value in batch.items():
                if isinstance(value, torch.Tensor):
                    batch[key] = value.to(device)
            
            with autocast(device_type="cuda", dtype=torch.float16):
                with torch.no_grad():
                    teacher_inputs = {"pixel_values": batch["teacher_pixel_values"], "input_ids": batch["teacher_input_ids"], "attention_mask": batch["teacher_attention_mask"], "image_sizes": batch["image_sizes"]}
                    teacher_outputs = teacher_model(**teacher_inputs)
                
                student_inputs = {"pixel_values": batch["student_pixel_values"], "input_ids": batch["student_input_ids"], "attention_mask": batch["student_attention_mask"]}
                student_outputs = student_model(**student_inputs)
            
            with autocast(device_type="cuda", enabled=False):
                loss_logits, loss_hidden = calculate_distillation_loss(
                    student_outputs, teacher_outputs, batch["student_prompt_len"], batch["teacher_prompt_len"]
                )
                total_loss = (LOSS_WEIGHT_LOGITS * loss_logits + LOSS_WEIGHT_HIDDEN * loss_hidden).float()
            
            total_train_loss += total_loss.item()
            scaled_loss = scaler.scale(total_loss) / GRAD_ACCUMULATION_STEPS
            scaled_loss.backward()

            if (step + 1) % GRAD_ACCUMULATION_STEPS == 0 or (step + 1) == len(train_dataloader):
                scaler.step(optimizer)
                scaler.update()
                scheduler.step()
                optimizer.zero_grad()
                pbar.set_postfix({"Loss": total_loss.item(), "Logits": loss_logits.item(), "Hidden": loss_hidden.item() if isinstance(loss_hidden, torch.Tensor) else loss_hidden})
        
        avg_train_loss = total_train_loss / len(train_dataloader)
        print(f"--- Epoch {epoch + 1} è¨“ç·´å®Œäº† ---\nAverage Training Loss: {avg_train_loss:.4f}")
        
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒå¾©æ´»ã—ãŸéƒ¨åˆ† â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        print("ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™...")
        if 'batch' in locals(): del batch
        if 'total_loss' in locals(): del total_loss
        if 'scaled_loss' in locals(): del scaled_loss
        if 'student_outputs' in locals(): del student_outputs
        if 'teacher_outputs' in locals(): del teacher_outputs
        if 'loss_logits' in locals(): del loss_logits
        if 'loss_hidden' in locals(): del loss_hidden
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ¨ ãƒ¡ãƒ¢ãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†ï¼")

        if eval_dataloader and eval_dataset.tasks:
            print(f"--- Epoch {epoch + 1} è©•ä¾¡é–‹å§‹ ---")
            avg_eval_loss = evaluate(student_model, teacher_model, eval_dataloader, device)
            print(f"--- Epoch {epoch + 1} è©•ä¾¡å®Œäº† ---\nâœ… Average Evaluation Loss: {avg_eval_loss:.4f}")

            epoch_output_dir = os.path.join(OUTPUT_DIR, f"epoch_{epoch+1}")
            os.makedirs(epoch_output_dir, exist_ok=True)
            print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {epoch_output_dir} ã«ä¿å­˜ä¸­...")
            student_model.save_pretrained(epoch_output_dir)
        else:
            print("è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… ã“ã“ã¾ã§ãŒå¾©æ´»ã—ãŸéƒ¨åˆ† â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

    print("\nğŸ‰ å…¨ã¦ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
if __name__ == '__main__':
    main()